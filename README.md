# TokenSpeed
Aiming to measure how "good" different tokenizers are, and how that depends on the task (coding, general datasets, high quality datasets, instruct, etc)
